---
layout: post
title:  "Talks"
date:   2021-10-10
description: 
tags: [AI, machine learning, autonomous driving, e-mobility, locality, mobility]
comments: true
share: true
authors: [Katharina Anderer]
typora-copy-images-to: ../media/katharina/
typora-root-url: ../
---



#### **Talks:** 

- **Dr. Thomas Grote**: "Ethics and Philosophy Lab" of the Cluster of Excellence "Machine Learning: New Perspectives for Science" at the University of Tübingen. (See Dr. Grote's homepage for further information: [https://sites.google.com/view/thomas-grote/startseite](https://sites.google.com/view/thomas-grote/startseite))

  <u>Keynote talk</u>: "Regulating AI Systems -- Lessons from Clinical Medicine"
  
  
  
- **Prof. Dr. Andreas Jungherr**: holds the Chair for the Governance of Complex and Innovative Technological Systems at the Institute for Political Science at the Otto-Friedrich-University Bamberg. (See Prof. Jungherr's homepage for further information: [https://andreasjungherr.net/](https://andreasjungherr.net/))

  

  

  <u>Keynote talk:</u> "AI and democracy: AI in politics and the politics of AI"

  *As artificial intelligence technology features in ever more aspects of social and economic life, AI becomes political. The use of AI by politicians and states is associated with both hopes and fears. Will AI increase social inequalities and allow politicians to split and manipulate the public? Or will AI allow politicians and states to tackle important problems with better information and new solutions? These fears and hopes find expression in public debate and political contestation. Scholars have an important role in this debate. They are on the frontlines of AI development and its implementation. At the same time, excessive fears or hopes regarding the impact of AI might make for great movie-plots but not so much for good policy advice or ethical guidelines. So, while we need to discuss the potential uses and effects of AI in democracies, we should not be carried away by excessive fears or hopes and thereby accidentally block progress or sow distrust in politics and elections*.
  
- **Prof. Michèle Finck**: 

  ~~<u>Keynote talk:</u> "The European Union's Regulatory Strategy for Artificial Intelligence"~~ unfortunately canceled due to shift of the workshop

- **Dr Christopher Burr** is an Ethics Fellow of the [Alan Turing Institute’s Public Policy Programme](https://www.turing.ac.uk/people/researchers/christopher-burr), and the Principal Investigator of a UKRI-funded project, supported by the Trustworthy Autonomous Systems Hub, titled ‘[Ethical Assurance of Digital Mental Healthcare](https://www.turing.ac.uk/research/research-projects/ethical-assurance-digital-mental-healthcare)’. His research expertise includes responsible research and innovation  (with a specific focus on data science and AI) and philosophy of  cognitive science. He works closely with a range of public sector  organisations to help realise more responsible uses of data science and  AI.

   

  <u>Keynote Talk:</u> 'Responsible AI: How to Design, Develop, and Deploy Data-Driven Systems'

   

  *There are a growing number of societal benefits and harms associated with AI. On the one hand, novel machine learning techniques promise to help  tackle climate change or improve clinical research. On the other hand,  recommendation engines can perpetuate hate speech or disinformation on  social media and automated facial recognition systems further exacerbate existing social biases. In an attempt to steer us away from the latter  and towards the former, many have called for more responsible AI  research and innovation.*

  

  *But how do researchers and practitioners identify the responsible uses of  AI from the irresponsible? What separates the morally permissible AI  project from the morally impermissible one?*

  

  *In this lecture, I will offer an intuitive and practical answer to this  question by setting out an approach to responsible scientific research  and technological innovation that is grounded in actual processes AI  design, development, and deployment. Moreover, this approach makes clear why the project of responsible AI is an inherently interdisciplinary  one, requiring input and expertise from a diverse range of backgrounds.  The goal is to present a procedural approach to responsible AI that can  help researchers and developers understand what is required to exercise  responsibility throughout the AI project lifecycle.* 

- **Paul C. Bauer**

  <u>Talk:</u> 'Evaluating survey measures of democratic quality & social cohesion using machine learning tools.'

  *Trust has become one of the foundational concepts of contemporary social theory. Still,*

  *empirical research on trust relies on a relatively small set of measures which are increasingly*
  *debated. Using data from an online, self-administered questionnaire which was conducted*
  *amongst a US representative sample (N = 1,500) and relying on a combination of open-ended*
  *probing data and supervised machine learning, our study compares the validity of*
  *standard measures of generalized social trust with more recent, situation-specific measures of*
  *trust. We find that measures that refer to strangers generally better reflect the conceptual idea*
  *of measuring trust in unknown others. Moreover, situation-specific measures even further*
  *reduce variation in associations, i.e., produce a more similar frame of reference which is*
  *desirable from a measurement perspective. We also present evidence that individuals’*
  *the association may differ in terms of sentiment, independently of the trustee category. Finally, we*
  *end with a discussion of the hard-to-solve challenge of formulating general but not too general*
  *survey measures.*

- **Dr. Simon Schaupp:**

  <u>Keynote Talk:</u> 'The technopolitics of algorithmic management'

   *Algorithms are organizing technologies. Like organizational rules or laws, they  define procedures according to which certain actions are to be executed. Yet, while we commonly identify laws or organizational rules as  political issues, which are negotiated in the context of conflicting  interests, we often fail to see the political nature of algorithms. This lecture aims to develop a political perspective on technologies of  algorithmic management in contexts of work. It reconstructs how  algorithmic management gained the importance it has in today’s world of  work, from wearable devices controlling individual workers to  overarching resource planning systems. The lecture will show how  technopolitical negotiations at various levels have shaped algorithmic  management so that it often resembles the logic of cybernetic management with its emphasis on feedback-based self-organization. Drawing on  ethnographic fieldwork in factories and delivery companies, the lecture  will emphasize that digitalization is not only shaped by engineers and  managers but also by the various appropriation strategies developed by  workers in their everyday use of technology. Thus, the lecture argues  that developing a political perspective on digitalization is a  prerequisite for democratic deliberation on desirable technological  futures.* 

 



#### Method sessions:



- **Zhijing Jin**: is a Ph.D. at Max Planck Institute & ETH. Her research goals are two-fold: (1) to expand the impact of NLP by promoting NLP for social good, and (2) to improve NLP models by connecting NLP with causal inference. See Zhijing Jin's homepage for further information: https://zhijing-jin.com/fantasy/bio/)

  *Language is the medium for many political activities, from campaigns to  news reports. Natural language processing (NLP) uses computational tools to parse text into key information that is needed for policymaking. In  this session, we will introduce common methods of NLP, including text  classification, topic modeling, event extraction, and text scaling.  Then, we will overview how these methods can be used for policymaking  through four major applications including data collection for  evidence-based policymaking, interpretation of political decisions,  policy communication, and investigation of policy effects. Finally, we  will highlight the challenges of NLP for policymaking in the coming  era.* 





 



